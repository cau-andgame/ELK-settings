# Sample Logstash configuration for creating a simple
# Beats -> Logstash -> Elasticsearch pipeline.

input {
  beats {
    port => 5044
  }
  #file {
  #  path => "/Users/senghyun/workspace/nlp-project/twitch-chat-data/original_data_multi/*/*.txt"
  #  start_position => "beginning"
  #}
}

filter {
  grok {
    match => ['message', "\[(?<timestamp>.*)] <(?<author>.*)> (?<content>.*)"]
  }
  grok {
    match => ["source", "(?<vid>\d*).txt"]
  }
  
  mutate {
    #rename => ['message', 'content']
    remove_field => ["host", "beat", "prospector", "log", "offset", "tags", "path", "input", "message"]
  }

  
  #aggregate {
  #  task_id => "%{vid}"
  #  code => "
  #       map['vid'] = event.get('vid')
  #       map['content'] ||= ''
  #       map['content'] << event.get('content') << ' '
  #       event.cancel()
  #  "
  #  push_previous_map_as_event => true
  #  push_map_as_event_on_timeout => true
  #  timeout_task_id_field => "vid"
  #  timeout => 3600 
  #  # 1 hour timeout, user activity will be considered finished one hour after the first event, even if events keep comming
  #  inactivity_timeout => 300 
  #  # 5 minutes timeout, user activity will be considered finished if no new events arrive 5 minutes after the last event

  #}
}

output {
  stdout { 
      codec => line {
          format => "%{vid} %{content} %{author} %{timestamp}"
      }
  }
  elasticsearch {
    hosts => ["http://192.168.0.2:9200"]
    index => "twitch1"
    document_type => "chat"
  }
#  elasticsearch {
#    hosts => ["http://192.168.0.2:9200"]
#    index => "autocompletion"
#    document_type => "search_keyword"
#  }
}
